{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-12-09T15:27:21.030746Z",
     "iopub.status.busy": "2024-12-09T15:27:21.030457Z",
     "iopub.status.idle": "2024-12-09T15:27:21.053476Z",
     "shell.execute_reply": "2024-12-09T15:27:21.052680Z",
     "shell.execute_reply.started": "2024-12-09T15:27:21.030712Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kaggle.json successfully created and configured!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Replace \"your_username\" and \"your_api_key\" with your actual Kaggle credentials\n",
    "kaggle_credentials = '''{\"username\":\"KULLANICI ADI\",\"key\":\"API ANAHTARI\"}''' # Profil -> Ayarlar -> API key oluştur. Sonrasında json dosyasındaki satırı buraya yapıştır. Kaggle notebook üzerinde çalıştırmak için gerekli. Localde çalıştırıyorsanız indirme işlemlerini atlayabilirsiniz.\n",
    "\n",
    "# Create the required directory\n",
    "os.makedirs(\"/root/.kaggle\", exist_ok=True)\n",
    "\n",
    "# Write the kaggle.json file\n",
    "with open(\"/root/.kaggle/kaggle.json\", \"w\") as f:\n",
    "    f.write(kaggle_credentials)\n",
    "\n",
    "# Set the proper permissions\n",
    "os.chmod(\"/root/.kaggle/kaggle.json\", 600)\n",
    "\n",
    "print(\"kaggle.json successfully created and configured!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ref                                                                                deadline             category                reward  teamCount  userHasEntered  \n",
      "---------------------------------------------------------------------------------  -------------------  ---------------  -------------  ---------  --------------  \n",
      "https://www.kaggle.com/competitions/ai-mathematical-olympiad-progress-prize-2      2025-04-01 23:59:00  Featured         2,117,152 Usd        706           False  \n",
      "https://www.kaggle.com/competitions/gemma-language-tuning                          2025-01-15 00:59:00  Analytics          150,000 Usd          0           False  \n",
      "https://www.kaggle.com/competitions/jane-street-real-time-market-data-forecasting  2025-01-13 23:59:00  Featured           120,000 Usd       2218           False  \n",
      "https://www.kaggle.com/competitions/nfl-big-data-bowl-2025                         2025-01-08 23:59:00  Analytics          100,000 Usd          0           False  \n",
      "https://www.kaggle.com/competitions/czii-cryo-et-object-identification             2025-02-05 23:59:00  Featured            75,000 Usd        333           False  \n",
      "https://www.kaggle.com/competitions/child-mind-institute-problematic-internet-use  2024-12-19 23:59:00  Featured            60,000 Usd       3202           False  \n",
      "https://www.kaggle.com/competitions/eedi-mining-misconceptions-in-mathematics      2024-12-12 23:59:00  Featured            55,000 Usd       1427           False  \n",
      "https://www.kaggle.com/competitions/santa-2024                                     2025-01-31 23:59:00  Featured            50,000 Usd        711           False  \n",
      "https://www.kaggle.com/competitions/fide-google-efficiency-chess-ai-challenge      2025-02-11 23:59:00  Featured            50,000 Usd        626           False  \n",
      "https://www.kaggle.com/competitions/equity-post-HCT-survival-predictions           2025-03-05 23:59:41  Research            50,000 Usd        326           False  \n",
      "https://www.kaggle.com/competitions/wsdm-cup-multilingual-chatbot-arena            2025-02-03 23:59:00  Featured            50,000 Usd        296           False  \n",
      "https://www.kaggle.com/competitions/llms-you-cant-please-them-all                  2025-03-04 23:59:00  Featured            50,000 Usd        247           False  \n",
      "https://www.kaggle.com/competitions/playground-series-s4e12                        2024-12-31 23:59:00  Playground                Swag        780           False  \n",
      "https://www.kaggle.com/competitions/titanic                                        2030-01-01 00:00:00  Getting Started      Knowledge      16398           False  \n",
      "https://www.kaggle.com/competitions/house-prices-advanced-regression-techniques    2030-01-01 00:00:00  Getting Started      Knowledge       6473           False  \n",
      "https://www.kaggle.com/competitions/home-data-for-ml-course                        2030-01-01 23:59:00  Getting Started      Knowledge       4748           False  \n",
      "https://www.kaggle.com/competitions/spaceship-titanic                              2030-01-01 00:00:00  Getting Started      Knowledge       2157           False  \n",
      "https://www.kaggle.com/competitions/digit-recognizer                               2030-01-01 00:00:00  Getting Started      Knowledge       1741           False  \n",
      "https://www.kaggle.com/competitions/nlp-getting-started                            2030-01-01 00:00:00  Getting Started      Knowledge        929           False  \n",
      "https://www.kaggle.com/competitions/store-sales-time-series-forecasting            2030-06-30 23:59:00  Getting Started      Knowledge        733           False  \n"
     ]
    }
   ],
   "source": [
    "!kaggle competitions list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-09T15:45:06.633809Z",
     "iopub.status.busy": "2024-12-09T15:45:06.633443Z",
     "iopub.status.idle": "2024-12-09T15:45:08.524787Z",
     "shell.execute_reply": "2024-12-09T15:45:08.523599Z",
     "shell.execute_reply.started": "2024-12-09T15:45:06.633777Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blg-454-e-fall-2024-term-project.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
     ]
    }
   ],
   "source": [
    "!kaggle competitions download -c blg-454-e-fall-2024-term-project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2024-12-09T15:29:09.339608Z",
     "iopub.status.busy": "2024-12-09T15:29:09.339197Z",
     "iopub.status.idle": "2024-12-09T15:29:16.007745Z",
     "shell.execute_reply": "2024-12-09T15:29:16.006836Z",
     "shell.execute_reply.started": "2024-12-09T15:29:09.339572Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  blg-454-e-fall-2024-term-project.zip\n",
      "  inflating: /kaggle/working/sampleSubmission.csv  \n",
      "  inflating: /kaggle/working/train_feats.npy  \n",
      "  inflating: /kaggle/working/train_labels.csv  \n",
      "  inflating: /kaggle/working/valtest_feats.npy  \n"
     ]
    }
   ],
   "source": [
    "!unzip -o blg-454-e-fall-2024-term-project.zip -d /kaggle/working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-09T15:45:13.407928Z",
     "iopub.status.busy": "2024-12-09T15:45:13.407223Z",
     "iopub.status.idle": "2024-12-09T15:45:14.504515Z",
     "shell.execute_reply": "2024-12-09T15:45:14.503506Z",
     "shell.execute_reply.started": "2024-12-09T15:45:13.407896Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "rm blg-454-e-fall-2024-term-project.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SAVE the version HERE AFTER UPLOAD the files on /kaggle/working to keep files on notebook.(they would be removed after leaving.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-09T16:17:22.472185Z",
     "iopub.status.busy": "2024-12-09T16:17:22.471505Z",
     "iopub.status.idle": "2024-12-09T16:17:22.790277Z",
     "shell.execute_reply": "2024-12-09T16:17:22.789527Z",
     "shell.execute_reply.started": "2024-12-09T16:17:22.472152Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Reshape\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Step 1: Load the Training Data (features and labels)\n",
    "# Assuming your .npy files are in the current working directory and each .npy file has 4 features.\n",
    "X_train = np.load('train_feats.npy',allow_pickle=True).item()  # Shape: (40000, 4, 512)\n",
    "\n",
    "# Load the labels from the CSV file\n",
    "labels_df = pd.read_csv('train_labels.csv')  # Assuming two columns: 'id' and 'label'\n",
    "y_train = labels_df['label'].values  # Labels for training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-09T16:17:48.972615Z",
     "iopub.status.busy": "2024-12-09T16:17:48.972276Z",
     "iopub.status.idle": "2024-12-09T16:17:48.979379Z",
     "shell.execute_reply": "2024-12-09T16:17:48.978453Z",
     "shell.execute_reply.started": "2024-12-09T16:17:48.972585Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "{'idx': array([    0,     1,     2, ..., 39997, 39998, 39999], dtype=int32), 'resnet_feature': array([[0.882933  , 1.7576884 , 0.03708305, ..., 3.1606352 , 0.0134144 ,\n",
      "        0.6481762 ],\n",
      "       [1.856296  , 0.08484737, 1.9896222 , ..., 1.5459379 , 0.82842904,\n",
      "        0.1313783 ],\n",
      "       [1.0885917 , 0.9853252 , 1.2479072 , ..., 0.28923872, 0.6282486 ,\n",
      "        0.23339106],\n",
      "       ...,\n",
      "       [0.22487839, 2.4103281 , 0.6937058 , ..., 0.403327  , 0.32973105,\n",
      "        0.9706055 ],\n",
      "       [0.6627451 , 0.5640983 , 0.6976747 , ..., 0.38385203, 1.6326518 ,\n",
      "        1.1779834 ],\n",
      "       [0.02847099, 3.0787446 , 0.28438878, ..., 0.9826051 , 0.01982202,\n",
      "        1.6046413 ]], dtype=float32), 'vit_feature': array([[ 0.39251244, -0.7359995 , -0.40713686, ...,  1.3599503 ,\n",
      "        -1.3506224 ,  0.34098613],\n",
      "       [ 0.536756  ,  0.20046183,  0.53705513, ..., -1.7052754 ,\n",
      "         0.09141281,  0.14567682],\n",
      "       [ 0.18865782,  0.40380907,  0.08730512, ...,  1.6099654 ,\n",
      "         0.55891013,  0.27936462],\n",
      "       ...,\n",
      "       [-0.6025765 ,  0.01734716, -0.33803308, ...,  0.85589916,\n",
      "         0.7427339 , -1.248568  ],\n",
      "       [ 1.5231186 ,  1.1395136 , -0.7313486 , ..., -0.11806969,\n",
      "         0.79510105, -1.8904324 ],\n",
      "       [-0.6422246 ,  0.14177863, -0.2094397 , ...,  0.44730175,\n",
      "        -0.01628912, -0.2093908 ]], dtype=float32), 'clip_feature': array([[ 0.36834767, -0.00485287, -0.54004794, ...,  0.47027186,\n",
      "         0.06563037,  0.4153874 ],\n",
      "       [ 0.21078074, -0.23845242, -0.23498438, ...,  0.89894676,\n",
      "         0.06032635,  0.22621469],\n",
      "       [ 0.23849042, -0.17168012, -0.33907497, ...,  0.45514852,\n",
      "         0.35196778, -0.05541086],\n",
      "       ...,\n",
      "       [-0.1104278 ,  0.14628522, -0.2647518 , ...,  0.9359021 ,\n",
      "        -0.16623342, -0.20308533],\n",
      "       [ 0.23675728, -0.33046892, -0.06131747, ...,  0.6114156 ,\n",
      "        -0.01266578, -0.1851928 ],\n",
      "       [-0.06907055,  0.06011807, -0.0398389 , ...,  0.8435011 ,\n",
      "         0.05702698,  0.14922932]], dtype=float32), 'dino_feature': array([[-1.5148295 ,  0.5156541 , -1.34948   , ..., -3.938788  ,\n",
      "         0.5832365 ,  1.818234  ],\n",
      "       [ 0.60461986,  0.6316875 , -2.3706322 , ..., -0.71917784,\n",
      "        -0.61893135,  2.9932036 ],\n",
      "       [ 0.35535327, -0.5768385 ,  0.9632951 , ...,  2.2688708 ,\n",
      "         0.86444795,  0.5634105 ],\n",
      "       ...,\n",
      "       [-0.91018575, -1.3741255 ,  3.4913125 , ..., -0.4677135 ,\n",
      "        -1.9953244 ,  0.1901589 ],\n",
      "       [-0.06525492,  0.9055043 ,  0.39283845, ...,  0.49695686,\n",
      "        -3.2006888 ,  0.14926304],\n",
      "       [ 1.2854265 ,  0.53157693, -0.09037519, ...,  0.23678556,\n",
      "        -2.7206366 , -1.1384493 ]], dtype=float32)}\n"
     ]
    }
   ],
   "source": [
    "# Check the type of the first element in the loaded data\n",
    "print(type(X_train))  # Should print <class 'numpy.ndarray'>\n",
    "# Inspect the first few elements to see if they are lists or arrays\n",
    "print(X_train)  # Should print the first item (should be a list or array with 4 features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-09T16:18:06.192217Z",
     "iopub.status.busy": "2024-12-09T16:18:06.191866Z",
     "iopub.status.idle": "2024-12-09T16:18:06.377341Z",
     "shell.execute_reply": "2024-12-09T16:18:06.376327Z",
     "shell.execute_reply.started": "2024-12-09T16:18:06.192188Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature matrix shape: (40000, 2560)\n",
      "Labels shape: (40000,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Load the features from the dictionary\n",
    "X_train_resnet = X_train['resnet_feature']  # Choose one feature set, or combine them\n",
    "X_train_vit = X_train['vit_feature']\n",
    "X_train_clip = X_train['clip_feature']\n",
    "X_train_dino = X_train['dino_feature']\n",
    "\n",
    "# Stack them into one feature matrix (if you want to use all features)\n",
    "X_train_combined = np.concatenate([X_train_resnet, X_train_vit, X_train_clip, X_train_dino], axis=1)\n",
    "\n",
    "# Load the labels from the CSV file\n",
    "labels_df = pd.read_csv('train_labels.csv')  # Assuming the labels are stored in 'labels.csv'\n",
    "y_train = labels_df['label'].values  # Adjust column name to match your CSV\n",
    "\n",
    "# Convert labels to integers if they are categorical\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "\n",
    "# Check the shape of the feature matrix and labels\n",
    "print(\"Feature matrix shape:\", X_train_combined.shape)\n",
    "print(\"Labels shape:\", y_train_encoded.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-09T16:19:42.472410Z",
     "iopub.status.busy": "2024-12-09T16:19:42.472054Z",
     "iopub.status.idle": "2024-12-09T16:19:42.477412Z",
     "shell.execute_reply": "2024-12-09T16:19:42.476577Z",
     "shell.execute_reply.started": "2024-12-09T16:19:42.472385Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of ResNet features: (40000, 512)\n",
      "Shape of ViT features: (40000, 768)\n",
      "Shape of CLIP features: (40000, 512)\n",
      "Shape of DINO features: (40000, 768)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Shape of ResNet features: {X_train_resnet.shape}\")\n",
    "print(f\"Shape of ViT features: {X_train_vit.shape}\")\n",
    "print(f\"Shape of CLIP features: {X_train_clip.shape}\")\n",
    "print(f\"Shape of DINO features: {X_train_dino.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-09T16:26:01.749395Z",
     "iopub.status.busy": "2024-12-09T16:26:01.748644Z",
     "iopub.status.idle": "2024-12-09T16:26:02.037390Z",
     "shell.execute_reply": "2024-12-09T16:26:02.036526Z",
     "shell.execute_reply.started": "2024-12-09T16:26:01.749361Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (32000, 2560)\n",
      "Validation set shape: (8000, 2560)\n"
     ]
    }
   ],
   "source": [
    "# Normalize the feature values to the range [0, 1]\n",
    "X_train_combined = X_train_combined / np.max(X_train_combined)\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "X_train_split, X_val_split, y_train_split, y_val_split = train_test_split(\n",
    "    X_train_combined, y_train_encoded, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(\"Training set shape:\", X_train_split.shape)\n",
    "print(\"Validation set shape:\", X_val_split.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-09T16:27:38.548691Z",
     "iopub.status.busy": "2024-12-09T16:27:38.548049Z",
     "iopub.status.idle": "2024-12-09T16:27:39.389750Z",
     "shell.execute_reply": "2024-12-09T16:27:39.388900Z",
     "shell.execute_reply.started": "2024-12-09T16:27:38.548658Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ reshape_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2560</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2558</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)       │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1279</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40928</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">5,238,912</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,290</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ reshape_1 (\u001b[38;5;33mReshape\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2560\u001b[0m, \u001b[38;5;34m1\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d (\u001b[38;5;33mConv1D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2558\u001b[0m, \u001b[38;5;34m32\u001b[0m)       │           \u001b[38;5;34m128\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d (\u001b[38;5;33mMaxPooling1D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1279\u001b[0m, \u001b[38;5;34m32\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40928\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │     \u001b[38;5;34m5,238,912\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │         \u001b[38;5;34m1,290\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,240,330</span> (19.99 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m5,240,330\u001b[0m (19.99 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,240,330</span> (19.99 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m5,240,330\u001b[0m (19.99 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Reshape\n",
    "\n",
    "# Define the model\n",
    "model = Sequential()\n",
    "\n",
    "# Reshape the input data to (batch_size, 2560, 1)\n",
    "model.add(Reshape((X_train_combined.shape[1], 1), input_shape=(X_train_combined.shape[1],)))\n",
    "\n",
    "# Add 1D Convolution layer (1D because data is a 1D feature array)\n",
    "model.add(Conv1D(32, 3, activation='relu'))  # 32 filters, kernel size 3\n",
    "model.add(MaxPooling1D(2))  # Max pooling with a pool size of 2\n",
    "\n",
    "# Flatten the output for fully connected layers\n",
    "model.add(Flatten())\n",
    "\n",
    "# Add dense layers for classification\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))  # 10 classes\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Summarize the model architecture\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-09T16:27:57.537371Z",
     "iopub.status.busy": "2024-12-09T16:27:57.537019Z",
     "iopub.status.idle": "2024-12-09T16:29:29.796266Z",
     "shell.execute_reply": "2024-12-09T16:29:29.795493Z",
     "shell.execute_reply.started": "2024-12-09T16:27:57.537341Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1733761679.333260     404 service.cc:145] XLA service 0x7f9de8003930 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1733761679.333553     404 service.cc:153]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 10/500\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - accuracy: 0.3770 - loss: 2.0753"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1733761681.226091     404 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - accuracy: 0.9307 - loss: 0.3262 - val_accuracy: 0.9841 - val_loss: 0.0507\n",
      "Epoch 2/10\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 18ms/step - accuracy: 0.9885 - loss: 0.0376 - val_accuracy: 0.9827 - val_loss: 0.0557\n",
      "Epoch 3/10\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 18ms/step - accuracy: 0.9942 - loss: 0.0195 - val_accuracy: 0.9866 - val_loss: 0.0457\n",
      "Epoch 4/10\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 18ms/step - accuracy: 0.9965 - loss: 0.0109 - val_accuracy: 0.9862 - val_loss: 0.0474\n",
      "Epoch 5/10\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 18ms/step - accuracy: 0.9983 - loss: 0.0058 - val_accuracy: 0.9852 - val_loss: 0.0556\n",
      "Epoch 6/10\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 18ms/step - accuracy: 0.9989 - loss: 0.0037 - val_accuracy: 0.9840 - val_loss: 0.0653\n",
      "Epoch 7/10\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 18ms/step - accuracy: 0.9984 - loss: 0.0058 - val_accuracy: 0.9865 - val_loss: 0.0558\n",
      "Epoch 8/10\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 18ms/step - accuracy: 0.9989 - loss: 0.0031 - val_accuracy: 0.9858 - val_loss: 0.0627\n",
      "Epoch 9/10\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 18ms/step - accuracy: 0.9990 - loss: 0.0034 - val_accuracy: 0.9861 - val_loss: 0.0619\n",
      "Epoch 10/10\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 18ms/step - accuracy: 0.9996 - loss: 0.0015 - val_accuracy: 0.9875 - val_loss: 0.0567\n"
     ]
    }
   ],
   "source": [
    "# Assuming your labels are in y_train and are integers representing class labels\n",
    "history = model.fit(X_train_combined, y_train, epochs=10, batch_size=64, validation_split=0.2)\n",
    "\n",
    "# Optionally, you can evaluate the model on a test dataset\n",
    "# test_loss, test_accuracy = model.evaluate(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-09T16:31:39.299785Z",
     "iopub.status.busy": "2024-12-09T16:31:39.298345Z",
     "iopub.status.idle": "2024-12-09T16:31:39.452914Z",
     "shell.execute_reply": "2024-12-09T16:31:39.452042Z",
     "shell.execute_reply.started": "2024-12-09T16:31:39.299736Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "dict_keys(['idx', 'resnet_feature', 'vit_feature', 'clip_feature', 'dino_feature'])\n"
     ]
    }
   ],
   "source": [
    "# Load the test data\n",
    "X_test = np.load('valtest_feats.npy', allow_pickle=True).item()\n",
    "\n",
    "# Check the structure of the loaded test data to verify it's similar to training data\n",
    "print(type(X_test))  # Should print <class 'dict'>\n",
    "print(X_test.keys())  # Should list the keys like 'resnet_feature', 'vit_feature', etc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-09T16:32:20.383165Z",
     "iopub.status.busy": "2024-12-09T16:32:20.382708Z",
     "iopub.status.idle": "2024-12-09T16:32:20.468138Z",
     "shell.execute_reply": "2024-12-09T16:32:20.467306Z",
     "shell.execute_reply.started": "2024-12-09T16:32:20.383135Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 2560)\n"
     ]
    }
   ],
   "source": [
    "# Extract the features from the test data\n",
    "X_test_resnet = X_test['resnet_feature']\n",
    "X_test_vit = X_test['vit_feature']\n",
    "X_test_clip = X_test['clip_feature']\n",
    "X_test_dino = X_test['dino_feature']\n",
    "\n",
    "# Combine the features (if necessary, depending on your approach)\n",
    "# This example assumes you want to concatenate all features together\n",
    "X_test_combined = np.concatenate([X_test_resnet, X_test_vit, X_test_clip, X_test_dino], axis=1)\n",
    "\n",
    "# Check the shape of X_test_combined\n",
    "print(X_test_combined.shape)  # Should print (20000, 2560) (assuming 40000 features from train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-09T16:32:30.880787Z",
     "iopub.status.busy": "2024-12-09T16:32:30.880112Z",
     "iopub.status.idle": "2024-12-09T16:32:32.720383Z",
     "shell.execute_reply": "2024-12-09T16:32:32.719350Z",
     "shell.execute_reply.started": "2024-12-09T16:32:30.880757Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "[2 0 9 9 8 7 8 5 0 4]\n"
     ]
    }
   ],
   "source": [
    "# Predict using the trained model\n",
    "predictions = model.predict(X_test_combined)\n",
    "\n",
    "# Convert predictions from one-hot encoded format to class labels\n",
    "predicted_labels = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Check the first few predicted labels\n",
    "print(predicted_labels[:10])  # Print the first 10 predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-09T16:32:58.204506Z",
     "iopub.status.busy": "2024-12-09T16:32:58.203837Z",
     "iopub.status.idle": "2024-12-09T16:32:58.225485Z",
     "shell.execute_reply": "2024-12-09T16:32:58.224827Z",
     "shell.execute_reply.started": "2024-12-09T16:32:58.204470Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create a DataFrame with the predictions and ids\n",
    "result_df = pd.DataFrame({'id': range(len(predicted_labels)), 'label': predicted_labels})\n",
    "\n",
    "# Save the predictions to a CSV file\n",
    "result_df.to_csv('result.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "dockerImageVersionId": 30805,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
